{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the Wisconsin breast cancer data from sklearn (binary classification problem), do a train/test split, and fit a logistic regression and 10 nearest neighbors model. Instead of using any built-in sklearn scoring methods, write your own accuracy, precision, recall, and F1 evaluation functions that take arrays of actual and predicted target labels as arguments. Score your models on the test set.\n",
    "    * e.g.  `def accuracy(actuals, preds)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.30, random_state=4444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "km = KNeighborsClassifier(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "km.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_lr_pred = lr.predict(X_test)\n",
    "y_km_pred = km.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall(actuals, preds):\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    for i in range(len(preds)):\n",
    "        if actuals[i] == 1:\n",
    "            if preds[i] == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "    return (tp / (tp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9696969696969697\n",
      "0.9595959595959596\n"
     ]
    }
   ],
   "source": [
    "print(recall(y_test, y_lr_pred))\n",
    "print(recall(y_test, y_km_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(actuals, preds):\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    for i in range(len(preds)):\n",
    "        if actuals[i] == 0 and preds[i] == 0:\n",
    "            tn += 1\n",
    "        if actuals[i] == 1 and preds[i] == 1:\n",
    "            tp += 1\n",
    "    return ((tp + tn)/len(preds))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9532163742690059\n",
      "0.935672514619883\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(y_test, y_lr_pred))\n",
    "print(accuracy(y_test, y_km_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision(actuals, preds):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] == 1:\n",
    "            if actuals[i] == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "    return (tp/(tp + fp))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9504950495049505\n",
      "0.9313725490196079\n"
     ]
    }
   ],
   "source": [
    "print(precision(y_test, y_lr_pred))\n",
    "print(precision(y_test, y_km_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1_score(actuals, preds):\n",
    "    precision_score = precision(actuals, preds)\n",
    "    recall_score = recall(actuals, preds)\n",
    "    return (2 * precision_score * recall_score / (precision_score + recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n",
      "0.945273631840796\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, y_lr_pred))\n",
    "print(f1_score(y_test, y_km_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write your own function for generating an ROC curve plot from model predictions without using sklearn's assistance. Remember that ROC plots true positive rate (recall) vs. false positive rate for a given probability decision threshold. So you should loop over a range of probability cutoffs from 1 to 0, convert a model's predicted probabilities (`model.predict_proba()[:,1]`) to target labels using each cutoff, and plot the results as a curve.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = lr.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in linspace(0)\n",
    "temp_y = y_p.map(lambda x: 0 if x < threshold else 1)\n",
    "return temp_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
